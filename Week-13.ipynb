{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 13: XPath part 1\n",
    "\n",
    "Over this week and next week we'll be going over XPath, but also discovering more about how to parse over multiple files and do more advanced stuff with lists and nested accumulator patterns.\n",
    "\n",
    "## What is XML?\n",
    "\n",
    "If you truly have zero knowledge of XML, I invite you to start with the a good skim of the [Wikipedia page](https://en.wikipedia.org/wiki/XML) on the subject. Don't pour over it, but it'll provide some important background vocabulary and context.  Anyhow, XML is ruleset for marking up documents in specific ways, and has been extended to a method of storing data in a very structured way.  Instead of having a row/column structure like a CSV file, you can have nested and thus much more complex data storage this way.\n",
    "\n",
    "Much of library metadata is stored in XML marked up documents, and that's the focus of the Metadata in Theory and Practice class offered at the iSchool.  Meanwhile, HTML is another markup language that works very similarly to XML.  Unless the HTML is severely malformed,techniques to extract data out of XML will also be useful for extracting data out of web pages.\n",
    "\n",
    "## What is XPath?\n",
    "\n",
    "XPath (https://en.wikipedia.org/wiki/XPath) is a query lanaguage (a la SQL, kind of) used to describe both locations for items and data extraction for XML documents/data.  This means that you can use it to both locate a specific element within an XML document but it also includes functions to pull out desired values.  Much of the time that's the text of that element, but sometimes you'll want other stuff.\n",
    "\n",
    "XPath is a system that is platform and tool independent, and thus you can actually find tools for it in the Oxygen XML editor, and there are a few other resources.  There are many Python tools that utilize XPath and have functions for applying XPath queries, but we're going to explore one of those.  \n",
    "\n",
    "## Installing lxml\n",
    "\n",
    "This will be our first instance into a third party module that you'll need to install.  lxml is a module available from PyPi, which means you can use pip to install it.  Please follow these directions:\n",
    "\n",
    "1. Open up your terminal or command prompt (this is the same as you did when you were testing your anaconda installation at the beginning of the semester.\n",
    "2. Type in `pip install lxml` and press enter.  You should not get an error.\n",
    "3. It should begin a downloading process and not end in a \"failed\" statement.\n",
    "4. Once you're back to the normal command prompt, type in `python` to open up IDLE.  Again, exactly how you did when testing out Anaconda.\n",
    "5. Type in `from lxml import etree` and press enter.  You should not see anything returned.  Let me know if you get an error an what that error is.\n",
    "6. Download a copy of the base script from the assignment and attempt to run it inside of PyCharm.  If you passed step 5 without an error, it should run without a problem.  \n",
    "    * Remember that this script requires that you have the files in a place the script can find them.  By default, it is expecting them to be in a folder a the same level of the script itself.  The script will run and execute with no data if it can't find the files, so a lack of error won't help you.  The start of the program has a statement to print out the file names it finds, so you should see something appear in your ouput.  Printing of an empty list means that it didn't find anything."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Designing around juicy pieces of code\n",
    "\n",
    "As you have discovered with other programs, there's a lot of data preparation and handling that go into our code before we get into the interesting pieces with XPath.  Just beacuse we're going to be using this XPath function to get out the data we want doesn't mean that the work is done for us.  That would be the case if we only needed one data point from one file.  But when we want to get multiple data points from multiple files, we need to have structures in place to collect that data and then export it to our desired structure.\n",
    "\n",
    "So it very much is the case that you'll have one really juicy piece of code sitting in the middle that's doing the substantive data work, but you still have a ton of code before and after to prepare and output the data.  What we need to do is explore larger design questions.\n",
    "\n",
    "You almost never know exactly how you're going to get from point A to point B in a program, but you know what point A is and what point B should be.  You may have to work a bit at the beginning, then a bit at the end, then fill things in the middle as you go.  You've see me do this during lecture, where we fill in some of our known structure and output at the start so we can focus on the meaty bits in the center.\n",
    "\n",
    "## So what do we know about this homework assignment?\n",
    "\n",
    "**Starting point:** You'll have 5 XML files that contain TEI-ed entries for a Digital Humanities conference.  These contain descriptive and administrative information about the entries.\n",
    "\n",
    "**Ending point:** You need to create 3 CSV documents with data about each of these files.  2 hour students will be pulling in 2 columns of data in each file and 4 credit hour students will be pulling out 4 columns of data in each.\n",
    "\n",
    "And the middle bits? We know it'll be something like looping through the files, gathering the data that we want, and then writing out all our files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Starting with multiple files\n",
    "\n",
    "We're used to reading in one file at a time, and naming them explicitly within our programs.  We could hard code all 5 file names, but what if they might change?  What if there are 5,000?  We can use some tools in Python to look up what these file names are as part of your program.  This makes your code more adaptable and flexible in the future.  You can also use patterns where you can pick a smaller random sample of your source data files to develop your code on, and gradually incrememnt it up to explore for outliers and check your logic.\n",
    "\n",
    "## the `glob` module\n",
    "\n",
    "There actually are several methods and modules to get file names from your computer using Python, but for simple needs, we can use the `glob` module (https://docs.python.org/3.5/library/glob.html). This isn't a default module, so you'll need to import it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Then the `glob.glob()` function will be what we want to use.  You pass this function a basic matching pattern and it'll return a list of matches.\n",
    "\n",
    "You'll make heavy use of the wildcard character of `*`.  This means \"anything of any length in this place. For example `\"*.txt\"` will match any file that ends with .txt.  Thus, `\"*.xml\"` will match any xml file.  You can also put a folder name in the matching pattern, but you'll need to play with how your full paths appear in your own system. My examples will be in Mac syntax, but windows will look different.\n",
    "\n",
    "We've got this folder called `drac_chaps` that we can explore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['drac_chaps']\n"
     ]
    }
   ],
   "source": [
    "print(glob.glob(\"drac_chaps\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "That isn't very interesting, but it is matching exactly what we've told it.  In this case, it just matches a single folder name. But we've got something! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(glob.glob(\"sneks_not_here\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This comes back with an empty list, so we can tell that there were no matches.\n",
    "\n",
    "This means that we need a wildcard to fill in some of the stuff that should come after `drac_chaps`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['drac_chaps']\n"
     ]
    }
   ],
   "source": [
    "print(glob.glob(\"drac_chaps*\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That didn't change anything, so we can tell that the `*` doesn't match the file delimiter.  In this case, I know my delimiter is `/`, so I can add that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['drac_chaps/Dracula-Chapter-1-Jonathan_Harkers_Journal.txt', 'drac_chaps/Dracula-Chapter-10-Mina_Murrays_Journal.txt', 'drac_chaps/Dracula-Chapter-11-Lucy_Westenras_Diary.txt', 'drac_chaps/Dracula-Chapter-12-Dr_Sewards_Diary.txt', 'drac_chaps/Dracula-Chapter-13-Dr_Sewards_Diary.txt', 'drac_chaps/Dracula-Chapter-14-Mina_Harkers_Journal.txt', 'drac_chaps/Dracula-Chapter-15-Dr_Sewards_Diary.txt', 'drac_chaps/Dracula-Chapter-16-Dr_Sewards_Diary.txt', 'drac_chaps/Dracula-Chapter-17-Dr_Sewards_Diary.txt', 'drac_chaps/Dracula-Chapter-18-Dr_Sewards_Diary.txt', 'drac_chaps/Dracula-Chapter-19-Jonathan_Harkers_Journal.txt', 'drac_chaps/Dracula-Chapter-2-Jonathan_Harkers_Journal.txt', 'drac_chaps/Dracula-Chapter-20-Jonathan_Harkers_Journal.txt', 'drac_chaps/Dracula-Chapter-21-Dr_Sewards_Diary.txt', 'drac_chaps/Dracula-Chapter-22-Jonathan_Harkers_Journal.txt', 'drac_chaps/Dracula-Chapter-23-Dr_Sewards_Diary.txt', 'drac_chaps/Dracula-Chapter-24-Dr_Sewards_Phonograph_Diary_spoken_by_Van_Helsing.txt', 'drac_chaps/Dracula-Chapter-25-Dr_Sewards_Diary.txt', 'drac_chaps/Dracula-Chapter-26-Dr_Sewards_Diary.txt', 'drac_chaps/Dracula-Chapter-27-Mina_Harkers_Journal.txt', 'drac_chaps/Dracula-Chapter-3-Jonathan_Harkers_Journal.txt', 'drac_chaps/Dracula-Chapter-4-Jonathan_Harkers_Journal.txt', 'drac_chaps/Dracula-Chapter-5-LettersLucy_and_Mina.txt', 'drac_chaps/Dracula-Chapter-6-Mina_Murrays_Journal.txt', 'drac_chaps/Dracula-Chapter-7-Cutting_from_The_Dailygraph_8_August.txt', 'drac_chaps/Dracula-Chapter-8-Mina_Murrays_Journal.txt', 'drac_chaps/Dracula-Chapter-9-Mina_Murrays_Journal.txt']\n"
     ]
    }
   ],
   "source": [
    "print(glob.glob(\"drac_chaps/*\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whoo! That got something.  Let's poke around."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drac_chaps/Dracula-Chapter-1-Jonathan_Harkers_Journal.txt\n",
      "27\n",
      "CHAPTER I\n",
      "\n",
      "JONATHAN HARKER'S JOURNAL\n",
      "\n",
      "(_Kept in shorthand._)\n",
      "\n",
      "\n",
      "_3 May. Bistritz._--Left Munich at 8:35 P. M., on 1st May, arriving at\n",
      "Vienna early next morning; should have arrived at 6:46, but train \n"
     ]
    }
   ],
   "source": [
    "found_files = glob.glob(\"drac_chaps/*\") # save to a variable to poke around\n",
    "\n",
    "print(found_files[0]) # we can see that it has the relative path to that file from our current position\n",
    "print(len(found_files)) # and it has 27 chapters\n",
    "\n",
    "drac_1 = open(found_files[0], 'r') # and we can read it in to check that it indeed works.\n",
    "\n",
    "print(drac_1.read()[:200])\n",
    "\n",
    "drac_1.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "`found_files` is just a list of these paths, so I can loop over it to open files, but I can also get information out of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['drac_chaps', 'Dracula-Chapter-1-Jonathan_Harkers_Journal.txt']\n",
      "['drac_chaps', 'Dracula-Chapter-10-Mina_Murrays_Journal.txt']\n",
      "['drac_chaps', 'Dracula-Chapter-11-Lucy_Westenras_Diary.txt']\n",
      "['drac_chaps', 'Dracula-Chapter-12-Dr_Sewards_Diary.txt']\n",
      "['drac_chaps', 'Dracula-Chapter-13-Dr_Sewards_Diary.txt']\n",
      "['drac_chaps', 'Dracula-Chapter-14-Mina_Harkers_Journal.txt']\n",
      "['drac_chaps', 'Dracula-Chapter-15-Dr_Sewards_Diary.txt']\n",
      "['drac_chaps', 'Dracula-Chapter-16-Dr_Sewards_Diary.txt']\n",
      "['drac_chaps', 'Dracula-Chapter-17-Dr_Sewards_Diary.txt']\n",
      "['drac_chaps', 'Dracula-Chapter-18-Dr_Sewards_Diary.txt']\n",
      "['drac_chaps', 'Dracula-Chapter-19-Jonathan_Harkers_Journal.txt']\n",
      "['drac_chaps', 'Dracula-Chapter-2-Jonathan_Harkers_Journal.txt']\n",
      "['drac_chaps', 'Dracula-Chapter-20-Jonathan_Harkers_Journal.txt']\n",
      "['drac_chaps', 'Dracula-Chapter-21-Dr_Sewards_Diary.txt']\n",
      "['drac_chaps', 'Dracula-Chapter-22-Jonathan_Harkers_Journal.txt']\n",
      "['drac_chaps', 'Dracula-Chapter-23-Dr_Sewards_Diary.txt']\n",
      "['drac_chaps', 'Dracula-Chapter-24-Dr_Sewards_Phonograph_Diary_spoken_by_Van_Helsing.txt']\n",
      "['drac_chaps', 'Dracula-Chapter-25-Dr_Sewards_Diary.txt']\n",
      "['drac_chaps', 'Dracula-Chapter-26-Dr_Sewards_Diary.txt']\n",
      "['drac_chaps', 'Dracula-Chapter-27-Mina_Harkers_Journal.txt']\n",
      "['drac_chaps', 'Dracula-Chapter-3-Jonathan_Harkers_Journal.txt']\n",
      "['drac_chaps', 'Dracula-Chapter-4-Jonathan_Harkers_Journal.txt']\n",
      "['drac_chaps', 'Dracula-Chapter-5-LettersLucy_and_Mina.txt']\n",
      "['drac_chaps', 'Dracula-Chapter-6-Mina_Murrays_Journal.txt']\n",
      "['drac_chaps', 'Dracula-Chapter-7-Cutting_from_The_Dailygraph_8_August.txt']\n",
      "['drac_chaps', 'Dracula-Chapter-8-Mina_Murrays_Journal.txt']\n",
      "['drac_chaps', 'Dracula-Chapter-9-Mina_Murrays_Journal.txt']\n"
     ]
    }
   ],
   "source": [
    "for path in found_files:\n",
    "    print(path.split(\"/\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Primary accumulators and secondary accumulators\n",
    "\n",
    "You've used this pattern before, but always worth an unpacking.\n",
    "\n",
    "There's a couple classic pattern explorations that intro to programming works with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a 0\n",
      "a 1\n",
      "a 2\n",
      "a 3\n",
      "done with sub loop!\n",
      "b 0\n",
      "b 1\n",
      "b 2\n",
      "b 3\n",
      "done with sub loop!\n",
      "c 0\n",
      "c 1\n",
      "c 2\n",
      "c 3\n",
      "done with sub loop!\n",
      "d 0\n",
      "d 1\n",
      "d 2\n",
      "d 3\n",
      "done with sub loop!\n"
     ]
    }
   ],
   "source": [
    "for letter in 'abcd':\n",
    "    for number in range(4):\n",
    "        print(letter, number)\n",
    "    print(\"done with sub loop!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "This is an example of a nested loop.  So on the outside we're looping over a, b, c, and d.  But for each of those letters, we're looping 4 times.  This makes for 16 total combinations between them.  We can use this pattern to loop over things we're...looping over! But mainly to process those values and collect something about them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem:  write a function that takes a string of characters and a range of numbers.  It produces a new character based on the ordinal value of that character multiplied by the value of the number.  Collect a list of these letters for each character.  \n",
    "\n",
    "So our primary loop is going to be the letters and our secondary loop will be the numbers.  This is because we want every number to apply to each letter. We want it the other way around, of course, but we've been asked to collect the data in one list for each original letter.  Making the original letter the primary loop makes things easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# what do we know we should start with?  a function\n",
    "\n",
    "def weird_char_thing(letters, range_thing):\n",
    "    all_lists = [] # a primary accumulator for my primary loop\n",
    "    for character in letters:\n",
    "        new_letters = [] # secondary loop collector\n",
    "        for number in range_thing:\n",
    "            new_ordinal = ord(character) * number\n",
    "            new_char = chr(new_ordinal)\n",
    "            new_letters.append(new_char) # making it a string\n",
    "        # once we've finished looping over all the numbers...\n",
    "        # we can add our secondary loop data to the primary loop accumulator\n",
    "        all_lists.append(new_letters)\n",
    "    return all_lists # return our final result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we look at our results, two questions:\n",
    "\n",
    "1. How many lists will be inside of `all_lists`?\n",
    "2. How many strings will be inside of each list in `all_lists`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['ģ', 'Ƅ', 'ǥ', 'Ɇ'],\n",
       " ['Ħ', 'ƈ', 'Ǫ', 'Ɍ'],\n",
       " ['ĩ', 'ƌ', 'ǯ', 'ɒ'],\n",
       " ['Ĭ', 'Ɛ', 'Ǵ', 'ɘ']]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weird_char_thing('abcd', range(3, 7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Â', 'ģ', 'Ƅ', 'ǥ', 'Ɇ'],\n",
       " ['Ä', 'Ħ', 'ƈ', 'Ǫ', 'Ɍ'],\n",
       " ['Æ', 'ĩ', 'ƌ', 'ǯ', 'ɒ'],\n",
       " ['È', 'Ĭ', 'Ɛ', 'Ǵ', 'ɘ']]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weird_char_thing('abcd', range(2, 7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['a', 'Â', 'ģ', 'Ƅ', 'ǥ', 'Ɇ'],\n",
       " ['b', 'Ä', 'Ħ', 'ƈ', 'Ǫ', 'Ɍ'],\n",
       " ['c', 'Æ', 'ĩ', 'ƌ', 'ǯ', 'ɒ'],\n",
       " ['d', 'È', 'Ĭ', 'Ɛ', 'Ǵ', 'ɘ']]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weird_char_thing('abcd', range(1, 7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['a', 'Â', 'ģ', 'Ƅ', 'ǥ', 'Ɇ', 'ʧ'],\n",
       " ['b', 'Ä', 'Ħ', 'ƈ', 'Ǫ', 'Ɍ', 'ʮ'],\n",
       " ['c', 'Æ', 'ĩ', 'ƌ', 'ǯ', 'ɒ', 'ʵ'],\n",
       " ['d', 'È', 'Ĭ', 'Ɛ', 'Ǵ', 'ɘ', 'ʼ'],\n",
       " ['e', 'Ê', 'į', 'Ɣ', 'ǹ', 'ɞ', '˃'],\n",
       " ['f', 'Ì', 'Ĳ', 'Ƙ', 'Ǿ', 'ɤ', 'ˊ'],\n",
       " ['g', 'Î', 'ĵ', 'Ɯ', 'ȃ', 'ɪ', 'ˑ']]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weird_char_thing('abcdefg', range(1, 8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Core primary/secondary loop pattern\n",
    "\n",
    "You'll notice a few things about the primary and secondary accumulator pattern:\n",
    "\n",
    "```python\n",
    "primary_collector = []\n",
    "for pri_item in primary:\n",
    "    secondary_collector = []\n",
    "    for sec_item in secondary:\n",
    "        secondary_collector.append(sec_item)\n",
    "    primary_collector.append(secondary_collector)\n",
    "```\n",
    "\n",
    "* The collector lists appear just before the for loops that will be adding things to them, and are at the same indent level as that for loop.  \n",
    "* Within the primary loop, the pattern is:\n",
    "    1. declare the empty accumulator for the secondary\n",
    "    2. loop over whatever the secondary stuff is\n",
    "    3. process the thing and appened each to the secondary collector\n",
    "    4. append the final secondary results to the primary\n",
    "    \n",
    "This is a class and standard primary/secondary loop pattern.  You might need to add in extra steps where you strip, split, or transform things, but these elements will be in there no matter what. \n",
    "\n",
    "Depending on how long your transformation processes are, you might want to create a transformation function to process your internal secondary or primary items so you can keep your structure cleaner.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# How does that apply to this?\n",
    "\n",
    "There is a notion of 1 to many in databases, which is actually quite a common feature in data.  For example, a single book may have many authors.  A class has many students.  A faculty member has many affiliations.  And so on.  XML is quite good at representing these relationships because it can nest things.  So let's break out some actual xml.  \n",
    "\n",
    "``` XML\n",
    "<book>\n",
    "    <author>Human, A.</author>\n",
    "    <title>This is not a book</title>\n",
    "</book>\n",
    "```\n",
    "\n",
    "This is a pretty clear case.  There's one book and one author for that book.  In this case, something like `\"//book/author/text()\"` would be sufficient for tracking down that author's name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Human, A.']\n"
     ]
    }
   ],
   "source": [
    "from lxml import etree\n",
    "\n",
    "xml = \"\"\"<book>\n",
    "    <author>Human, A.</author>\n",
    "    <title>This is not a book</title>\n",
    "</book>\"\"\"\n",
    "\n",
    "tree = etree.fromstring(xml)\n",
    "print(tree.xpath('//book/author/text()'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "And exactly that!  **But** let's take a closer look at what just happened with this result.  Note that I didn't just get a string of the thing that I wanted.  I got a list with a single string within it.  This can tell you that the `xpath()` function is well prepared for getting multiple results.  \n",
    "\n",
    "The fact that my data may have multiple values for these items means that I need to completely change my approach for getting this data out.  We've used SQL last week that would print back to us a tbale of results.  We, as humans, were planning on processing that. We didn't have to care.  The functions we wanted to apply to each column were ready to handle instances of zero, one, or many results.  SQL just handles it.\n",
    "\n",
    "But this is a different world, where we need to write lower level code.  So you, as the programmer, need to deal with that kind of thing.  Let's practice a primary and secondary loop pattern over this sort of returned data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42 Human, A.\n",
      "23 Human, A.\n",
      "23 Human, Not.\n"
     ]
    }
   ],
   "source": [
    "xml = [\"\"\"<book>\n",
    "    <book_id>42</book_id>\n",
    "    <author>Human, A.</author>\n",
    "    <title>This is not a book</title>\n",
    "</book>\"\"\",\n",
    "\n",
    "\"\"\"<book>\n",
    "    <book_id>23</book_id>\n",
    "    <author>Human, A.</author>\n",
    "    <author>Human, Not.</author>\n",
    "    <title>This is not a book</title>\n",
    "</book>\"\"\"]\n",
    "\n",
    "# so we've got multiple chunks of xml here\n",
    "# we know that book_id will only happen once (because I'm saying so here)\n",
    "# but we may have multiple authors\n",
    "\n",
    "for data_chunk in xml:\n",
    "    tree = etree.fromstring(data_chunk)\n",
    "    author_list = tree.xpath('//book/author/text()')\n",
    "    book_id_list = tree.xpath('//book/book_id/text()')\n",
    "    if len(book_id_list) != 1:\n",
    "        print(\"Too many book_id values, skipping\")\n",
    "        continue\n",
    "    else:\n",
    "        book_id = book_id_list[0]\n",
    "    for author in author_list:\n",
    "        print(book_id, author)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "This looks pretty good because all the values that I'm getting back are all strings.  All those lists are gone.  This means that the results I'm spitting out from these loops are primed and ready to be written out to a file.  No futher processing.\n",
    "\n",
    "Also note that it worked just fine when I had a list of one item.  \n",
    "\n",
    "Had we not used this primary/secondary patter, we would have ended up with this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42 ['Human, A.']\n",
      "23 ['Human, A.', 'Human, Not.']\n"
     ]
    }
   ],
   "source": [
    "for data_chunk in xml:\n",
    "    tree = etree.fromstring(data_chunk)\n",
    "    author_list = tree.xpath('//book/author/text()')\n",
    "    book_id_list = tree.xpath('//book/book_id/text()')\n",
    "    if len(book_id_list) != 1:\n",
    "        print(\"Too many book_id values, skipping\")\n",
    "        continue\n",
    "    else:\n",
    "        book_id = book_id_list[0]\n",
    "    print(book_id, author_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I could make this work by running a join on those lists:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42 Human, A.\n",
      "23 Human, A.;Human, Not.\n"
     ]
    }
   ],
   "source": [
    "for data_chunk in xml:\n",
    "    tree = etree.fromstring(data_chunk)\n",
    "    author_list = tree.xpath('//book/author/text()')\n",
    "    book_id_list = tree.xpath('//book/book_id/text()')\n",
    "    if len(book_id_list) != 1:\n",
    "        print(\"Too many book_id values, skipping\")\n",
    "        continue\n",
    "    else:\n",
    "        book_id = book_id_list[0]\n",
    "    print(book_id, \";\".join(author_list)) # look here for the change"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depending on your data design you may want:\n",
    "\n",
    "1. To have any multiple values represented in separate rows\n",
    "    * So you'd need to use the primary/secondary loop pattern\n",
    "2. Having any multiple values in a single cell is fine\n",
    "    * Then you can do the \"delim\".join(stuff) pattern"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In Conclusion...\n",
    "\n",
    "So now that we have a basis of strategy and tool, we can explore more about xpath itself in our next lesson.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
